{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook breaks down how `cross_entropy` function (corresponding to `CrossEntropyLoss` used for classification) is implemented in pytorch, and how it is related to softmax, log_softmax, and nll (negative log-likelihood)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 3])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size, n_classes = 5, 3\n",
        "x = torch.randn(batch_size, n_classes)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.3796, -1.4432,  0.8661],\n",
              "        [-1.6321, -0.2053,  0.5196],\n",
              "        [-0.8158,  1.2398,  1.0848],\n",
              "        [ 1.5698, -0.2200, -0.1800],\n",
              "        [-1.2378,  1.9793, -1.3160]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 1, 1])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target = torch.randint(n_classes, size=(batch_size,), dtype=torch.long)\n",
        "target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `softmax` + `nl` (negative likelihood)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This version is most similar to the math formula, but not numerically stable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.5794)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def softmax(x): return x.exp() / (x.exp().sum(-1)).unsqueeze(-1)\n",
        "def nl(input, target): return -input[range(target.shape[0]), target].log().mean()\n",
        "\n",
        "pred = softmax(x)\n",
        "loss=nl(pred, target)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.5794)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = softmax(x)\n",
        "loss=nl(pred, target)\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `log_softmax` + `nll` (negative log-likelihood)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://pytorch.org/docs/stable/nn.html?highlight=logsoftmax#torch-nn-functional\n",
        ">While mathematically equivalent to `log(softmax(x))`, doing these two operations separately is slower, and numerically unstable. This function uses an alternative formulation to compute the output and gradient correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.5794)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def log_softmax(x): return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "def nll(input, target): return -input[range(target.shape[0]), target].mean()\n",
        "\n",
        "pred = log_softmax(x)\n",
        "loss = nll(pred, target)\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `F.log_softmax` + `F.nll_loss`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above but in pytorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.5794)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred = F.log_softmax(x, dim=-1)\n",
        "loss = F.nll_loss(pred, target)\n",
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### `F.cross_entropy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pytorch's single cross_entropy function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1.5794)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "F.cross_entropy(x, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reference:\n",
        "- https://github.com/fastai/fastai_old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "_draft": {
      "nbviewer_url": "https://gist.github.com/217dcc6ae9171d7a46ce42e215c1fee0"
    },
    "gist": {
      "data": {
        "description": "Cross entropy implementation in pytorch",
        "public": true
      },
      "id": "217dcc6ae9171d7a46ce42e215c1fee0"
    },
    "kernelspec": {
      "display_name": "Python [conda env:fastaiv1]",
      "language": "python",
      "name": "conda-env-fastaiv1-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
